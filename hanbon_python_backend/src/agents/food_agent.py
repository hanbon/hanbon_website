#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@file: food_agent.py
@description: ç¾é£ŸAIä»£ç†æ ¸å¿ƒç±»
@author: AI Assistant
@created: 2024
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, AsyncGenerator, Any
import openai
from pydantic import BaseModel

logger = logging.getLogger(__name__)

class ConversationContext(BaseModel):
    """å¯¹è¯ä¸Šä¸‹æ–‡æ¨¡å‹"""
    user_id: str
    session_id: str
    messages: List[Dict[str, str]] = []
    preferences: Dict[str, Any] = {}
    current_location: Optional[str] = None
    enabled_tools: List[str] = []

class FoodAgent:
    """
    ç¾é£ŸAIä»£ç†ç±»
    é›†æˆPlan(è®¡åˆ’)ã€Memory(è®°å¿†)ã€Action(è¡ŒåŠ¨)ä¸‰å¤§åŠŸèƒ½
    """
    
    def __init__(self, config, memory_client, mcp_manager, model_manager=None):
        """
        åˆå§‹åŒ–ç¾é£ŸAIä»£ç†
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆåŒ…å«AIæ¨¡å‹é…ç½®ï¼‰
            memory_client: è®°å¿†å®¢æˆ·ç«¯
            mcp_manager: MCPå·¥å…·ç®¡ç†å™¨
            model_manager: æ¨¡å‹ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        """
        self.config = config
        self.memory_client = memory_client
        self.mcp_manager = mcp_manager
        self.model_manager = model_manager
        
        if model_manager:
            # ä½¿ç”¨æ–°çš„æ¨¡å‹ç®¡ç†å™¨
            self.ai_clients = model_manager.ai_clients
        else:
            # å…¼å®¹æ€§ï¼šä½¿ç”¨æ—§çš„åˆå§‹åŒ–æ–¹æ³•
            self.ai_clients = {}
            self._init_ai_clients()
        
        # å…¼å®¹æ€§ï¼šä¿æŒdeepseek_clientå±æ€§
        self.deepseek_client = self.ai_clients.get('deepseek')
        
        # æ´»è·ƒçš„å¯¹è¯ä¸Šä¸‹æ–‡
        self.active_contexts: Dict[str, ConversationContext] = {}
        
        # AIä»£ç†çš„äººæ ¼è®¾å®š
        self.personality = {
            "friendly_food_expert": self._get_friendly_personality(),
            "professional_food_expert": self._get_professional_personality()
        }
        
        self.current_personality = "friendly_food_expert"
    
    def _init_ai_clients(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„AIå®¢æˆ·ç«¯"""
        for model_id, model_config in self.config.AI_MODELS.items():
            if model_config.get('enabled', False) and model_config.get('api_key'):
                try:
                    self.ai_clients[model_id] = openai.AsyncOpenAI(
                        api_key=model_config['api_key'],
                        base_url=model_config['api_base']
                    )
                    logger.info(f"æˆåŠŸåˆå§‹åŒ– {model_config['name']} å®¢æˆ·ç«¯")
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ– {model_config['name']} å®¢æˆ·ç«¯å¤±è´¥: {e}")
    
    def _get_ai_client(self, model_name: str = None):
        """è·å–æŒ‡å®šæ¨¡å‹çš„AIå®¢æˆ·ç«¯"""
        if self.model_manager:
            # ä½¿ç”¨æ–°çš„æ¨¡å‹ç®¡ç†å™¨
            return self.model_manager.get_ai_client(model_name)
        else:
            # å…¼å®¹æ€§ï¼šä½¿ç”¨æ—§çš„æ–¹æ³•
            if not model_name:
                model_name = self.config.DEFAULT_MODEL
            
            if model_name in self.ai_clients:
                return self.ai_clients[model_name], self.config.AI_MODELS[model_name]
            else:
                # å›é€€åˆ°é»˜è®¤æ¨¡å‹
                default_model = self.config.DEFAULT_MODEL
                if default_model in self.ai_clients:
                    logger.warning(f"æ¨¡å‹ {model_name} ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ {default_model}")
                    return self.ai_clients[default_model], self.config.AI_MODELS[default_model]
                else:
                    raise ValueError(f"æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹å®¢æˆ·ç«¯")
        
    def _get_friendly_personality(self) -> str:
        """è·å–å‹å¥½å‹äººæ ¼è®¾å®š"""
        return """ä½ æ˜¯é£Ÿæ…§ç¾é£ŸAIåŠ©æ‰‹ï¼Œä¸€ä¸ªçƒ­æƒ…å‹å¥½çš„ç¾é£Ÿä¸“å®¶ã€‚ä½ çš„ç‰¹ç‚¹ï¼š

1. **ä¸“ä¸šçŸ¥è¯†**ï¼šç²¾é€šä¸­åæ–™ç†ã€ä¸–ç•Œå„åœ°ç¾é£Ÿã€è¥å…»æ­é…ã€çƒ¹é¥ªæŠ€å·§
2. **æ€§æ ¼ç‰¹ç‚¹**ï¼šçƒ­æƒ…ã€è€å¿ƒã€å¹½é»˜ã€å–„äºå€¾å¬
3. **äº¤æµé£æ ¼**ï¼šç”¨æ¸©æš–çš„è¯­è°ƒï¼Œé€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°äº²åˆ‡
4. **æœåŠ¡ç†å¿µ**ï¼šä»¥ç”¨æˆ·éœ€æ±‚ä¸ºä¸­å¿ƒï¼Œæä¾›ä¸ªæ€§åŒ–çš„ç¾é£Ÿå»ºè®®

ä½ èƒ½å¤Ÿï¼š
- ğŸ³ æ¨èé€‚åˆçš„èœè°±å’Œåšæ³•
- ğŸ—ºï¸ æ ¹æ®åœ°ç†ä½ç½®æ¨èå½“åœ°ç¾é£Ÿ
- ğŸŒ¡ï¸ ç»“åˆå¤©æ°”æƒ…å†µç»™å‡ºé¥®é£Ÿå»ºè®®
- ğŸ“· è¯†åˆ«é£Ÿç‰©å›¾ç‰‡å¹¶æä¾›ç›¸å…³ä¿¡æ¯
- ğŸ’¡ è®°ä½ç”¨æˆ·çš„å£å‘³åå¥½å’Œé¥®é£Ÿä¹ æƒ¯
- ğŸ¯ åˆ¶å®šä¸ªæ€§åŒ–çš„é¥®é£Ÿè®¡åˆ’

è¯·å§‹ç»ˆä¿æŒå‹å¥½ã€ä¸“ä¸šçš„æ€åº¦ï¼Œç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å¸®åŠ©ç”¨æˆ·äº«å—ç¾é£Ÿç”Ÿæ´»ï¼"""

    def _get_professional_personality(self) -> str:
        """è·å–ä¸“ä¸šå‹äººæ ¼è®¾å®š"""
        return """æ‚¨å¥½ï¼Œæˆ‘æ˜¯é£Ÿæ…§ç¾é£ŸAIä¸“ä¸šé¡¾é—®ã€‚ä½œä¸ºä¸“ä¸šçš„ç¾é£Ÿåˆ†æç³»ç»Ÿï¼Œæˆ‘å…·å¤‡ï¼š

1. **ä¸“ä¸šèƒ½åŠ›**ï¼šæ·±åº¦ç¾é£ŸçŸ¥è¯†åº“ã€è¥å…»å­¦åˆ†æã€çƒ¹é¥ªå·¥è‰ºç ”ç©¶
2. **æœåŠ¡æ ‡å‡†**ï¼šå‡†ç¡®ã€é«˜æ•ˆã€ä¸ªæ€§åŒ–ã€æ•°æ®é©±åŠ¨
3. **æŠ€æœ¯ä¼˜åŠ¿**ï¼šå¤šæ¨¡æ€åˆ†æã€æ™ºèƒ½æ¨èã€å®æ—¶ä¿¡æ¯è·å–
4. **ä¸“ä¸šé¢†åŸŸ**ï¼šèœè°±åˆ†æã€è¥å…»è¯„ä¼°ã€é£Ÿææ­é…ã€çƒ¹é¥ªæŒ‡å¯¼

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ç²¾å‡†çš„é£Ÿè°±åŒ¹é…ä¸ä¼˜åŒ–å»ºè®®
- åŸºäºåœ°ç†ä½ç½®çš„é¤é¥®ä¿¡æ¯æŸ¥è¯¢
- è¥å…»æˆåˆ†åˆ†æä¸å¥åº·å»ºè®®
- é£Ÿç‰©å›¾åƒè¯†åˆ«ä¸æˆåˆ†åˆ†æ
- ä¸ªæ€§åŒ–é¥®é£Ÿæ–¹æ¡ˆåˆ¶å®š
- ä¸“ä¸šçƒ¹é¥ªæŠ€å·§æŒ‡å¯¼

æˆ‘å°†ä¸ºæ‚¨æä¾›æœ€ä¸“ä¸šã€å‡†ç¡®çš„ç¾é£Ÿå’¨è¯¢æœåŠ¡ã€‚"""

    async def get_context(self, user_id: str, session_id: str) -> ConversationContext:
        """è·å–æˆ–åˆ›å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        context_key = f"{user_id}:{session_id}"
        
        if context_key not in self.active_contexts:
            # ä»è®°å¿†ä¸­æ¢å¤ä¸Šä¸‹æ–‡
            memories = await self.memory_client.get_user_memories(user_id)
            preferences = {}
            
            # ä»è®°å¿†ä¸­æå–ç”¨æˆ·åå¥½
            for memory in memories:
                if memory.get('type') == 'preference':
                    preferences.update(memory.get('content', {}))
            
            self.active_contexts[context_key] = ConversationContext(
                user_id=user_id,
                session_id=session_id,
                preferences=preferences
            )
        
        return self.active_contexts[context_key]

    async def process_message(
        self, 
        message: str, 
        user_id: str = "default", 
        session_id: str = "default",
        enabled_tools: List[str] = None,
        model: str = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            enabled_tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
            context = await self.get_context(user_id, session_id)
            context.enabled_tools = enabled_tools or []
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
            context.messages.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })
            
            # è®¡åˆ’é˜¶æ®µ - åˆ†æç”¨æˆ·æ„å›¾å’Œéœ€è¦çš„å·¥å…·
            plan = await self._plan_response(message, context, model)
            
            # è¡ŒåŠ¨é˜¶æ®µ - æ‰§è¡Œå¿…è¦çš„å·¥å…·è°ƒç”¨
            action_results = await self._execute_actions(plan, context, model)
            
            # ç”Ÿæˆå›å¤
            response = await self._generate_response(message, context, plan, action_results, model)
            
            # è®°å¿†é˜¶æ®µ - æ›´æ–°ç”¨æˆ·è®°å¿†
            memory_updated = await self._update_memory(context, message, response)
            
            return {
                "response": response,
                "tools_used": plan.get("tools", []),
                "memory_updated": memory_updated,
                "session_id": session_id,
                "plan": plan
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            return {
                "response": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}",
                "tools_used": [],
                "memory_updated": False,
                "session_id": session_id
            }

    async def stream_message(
        self,
        message: str,
        user_id: str = "default",
        session_id: str = "default",
        enabled_tools: List[str] = None,
        model: str = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¸¦æ€ç»´é“¾ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            user_id: ç”¨æˆ·ID  
            session_id: ä¼šè¯ID
            enabled_tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
            
        Yields:
            æµå¼å“åº”å—
        """
        try:
            # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
            context = await self.get_context(user_id, session_id)
            context.enabled_tools = enabled_tools or []
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
            context.messages.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })
            
            # å‘é€å¼€å§‹ä¿¡å·
            yield {
                "type": "start",
                "content": "å¼€å§‹å¤„ç†æ‚¨çš„è¯·æ±‚..."
            }
            
            # æ€ç»´é“¾é˜¶æ®µ - åˆ†æç”¨æˆ·æ„å›¾
            yield {
                "type": "thinking_step",
                "step": 1,
                "title": "ç†è§£ç”¨æˆ·éœ€æ±‚",
                "content": "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...",
                "status": "processing"
            }
            
            # æµå¼ç”Ÿæˆæ„å›¾åˆ†æ
            thinking_analysis_chunks = []
            async for chunk in self._stream_user_intent_analysis(message, context, model):
                thinking_analysis_chunks.append(chunk)
                yield {
                    "type": "thinking_step", 
                    "step": 1,
                    "title": "ç†è§£ç”¨æˆ·éœ€æ±‚",
                    "content": "".join(thinking_analysis_chunks),
                    "status": "processing"
                }
            
            yield {
                "type": "thinking_step",
                "step": 1,
                "title": "ç†è§£ç”¨æˆ·éœ€æ±‚",
                "content": "".join(thinking_analysis_chunks),
                "status": "completed"
            }
            
            # æ€ç»´é“¾é˜¶æ®µ - åˆ¶å®šè®¡åˆ’
            yield {
                "type": "thinking_step", 
                "step": 2,
                "title": "åˆ¶å®šè§£å†³æ–¹æ¡ˆ",
                "content": "æ ¹æ®éœ€æ±‚åˆ†æï¼Œæ­£åœ¨åˆ¶å®šæœ€ä½³çš„å›ç­”ç­–ç•¥...",
                "status": "processing"
            }
            
            plan = await self._plan_response_with_thinking(message, context, model)
            
            # æµå¼ç”Ÿæˆè®¡åˆ’æ€è€ƒè¿‡ç¨‹
            plan_thinking_content = ""
            plan_parts = [
                f"æˆ‘çš„è®¡åˆ’ï¼š",
                f"â€¢ ç”¨æˆ·æ„å›¾ï¼š{plan.get('intent', 'æœªçŸ¥')}",
                f"â€¢ éœ€è¦ä½¿ç”¨çš„å·¥å…·ï¼š{', '.join(plan.get('tools', [])) if plan.get('tools') else 'æ— '}",
                f"â€¢ å›ç­”ç±»å‹ï¼š{plan.get('response_type', 'text')}",
                f"â€¢ ç­–ç•¥ï¼š{plan.get('strategy', 'ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜')}"
            ]
            
            for part in plan_parts:
                plan_thinking_content += part + "\n"
                yield {
                    "type": "thinking_step",
                    "step": 2,
                    "title": "åˆ¶å®šè§£å†³æ–¹æ¡ˆ", 
                    "content": plan_thinking_content.strip(),
                    "status": "processing"
                }
                # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
                await asyncio.sleep(0.3)
            
            yield {
                "type": "thinking_step",
                "step": 2, 
                "title": "åˆ¶å®šè§£å†³æ–¹æ¡ˆ",
                "content": plan_thinking_content.strip(),
                "status": "completed"
            }
            
            # æ€ç»´é“¾é˜¶æ®µ - æ‰§è¡Œå·¥å…·
            action_results = {}
            if plan.get("tools"):
                yield {
                    "type": "thinking_step",
                    "step": 3,
                    "title": "æ”¶é›†ä¿¡æ¯",
                    "content": f"æ­£åœ¨ä½¿ç”¨ {', '.join(plan['tools'])} å·¥å…·æ”¶é›†ç›¸å…³ä¿¡æ¯...",
                    "status": "processing"
                }
                
                action_results = await self._execute_actions_with_thinking(plan, context, model)
                
                # åˆ†æå·¥å…·ç»“æœ
                tools_summary = []
                for tool_name, result in action_results.items():
                    if 'error' not in result:
                        if tool_name == 'image_search':
                            count = len(result.get('display_data', {}).get('images', []))
                            tools_summary.append(f"å›¾ç‰‡æœç´¢ï¼šæ‰¾åˆ° {count} å¼ ç›¸å…³å›¾ç‰‡")
                        elif tool_name == 'food_recommendation':
                            count = result.get('display_data', {}).get('total_count', 0)
                            tools_summary.append(f"ç¾é£Ÿæ¨èï¼šç”Ÿæˆ {count} ä¸ªæ¨è")
                        elif tool_name == 'recipe_generator':
                            dish_name = result.get('display_data', {}).get('recipe', {}).get('dish_name', 'èœè°±')
                            tools_summary.append(f"èœè°±ç”Ÿæˆï¼šåˆ¶ä½œ {dish_name} çš„è¯¦ç»†èœè°±")
                        else:
                            tools_summary.append(f"{tool_name}ï¼šæ‰§è¡ŒæˆåŠŸ")
                    else:
                        tools_summary.append(f"{tool_name}ï¼šæ‰§è¡Œå¤±è´¥")
                
                tools_result_text = f"""
ä¿¡æ¯æ”¶é›†å®Œæˆï¼š
{chr(10).join(['â€¢ ' + summary for summary in tools_summary])}

ç°åœ¨æˆ‘æœ‰äº†è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚
"""
                
                yield {
                    "type": "thinking_step",
                    "step": 3,
                    "title": "æ”¶é›†ä¿¡æ¯", 
                    "content": tools_result_text.strip(),
                    "status": "completed"
                }
                
                # å‘é€å·¥å…·ç»“æœ
                tool_results_list = []
                for tool_name, result in action_results.items():
                    tool_results_list.append(result)
                
                yield {
                    "type": "action_result",
                    "content": tool_results_list
                }
            
            # æ€ç»´é“¾é˜¶æ®µ - ç”Ÿæˆå›å¤
            yield {
                "type": "thinking_step",
                "step": 4,
                "title": "ç»„ç»‡å›ç­”",
                "content": "æ­£åœ¨æ•´ç†ä¿¡æ¯ï¼Œä¸ºæ‚¨ç”Ÿæˆæœ€åˆé€‚çš„å›ç­”...",
                "status": "processing"
            }
            
            # æµå¼ç”Ÿæˆå›å¤å¹¶æ”¶é›†å®Œæ•´å“åº”
            response_chunks = []
            try:
                async for chunk in self._stream_response_with_thinking(message, context, plan, action_results, model):
                    response_chunks.append(chunk)
                    yield {
                        "type": "response_chunk", 
                        "content": chunk
                    }
                
                # ç¡®ä¿æ€ç»´é“¾ç¬¬å››æ­¥å®Œæˆ
                yield {
                    "type": "thinking_step",
                    "step": 4,
                    "title": "ç»„ç»‡å›ç­”",
                    "content": "å›ç­”ç”Ÿæˆå®Œæˆï¼å·²ä¸ºæ‚¨æ•´ç†å¥½å®Œæ•´çš„ä¿¡æ¯ï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚",
                    "status": "completed"
                }
                
            except Exception as stream_error:
                logger.error(f"æµå¼å›å¤ç”Ÿæˆå¤±è´¥: {stream_error}")
                # å³ä½¿å‡ºé”™ä¹Ÿè¦å®Œæˆæ€ç»´é“¾
                yield {
                    "type": "thinking_step",
                    "step": 4,
                    "title": "ç»„ç»‡å›ç­”",
                    "content": f"å›ç­”ç”Ÿæˆè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œä½†æˆ‘å·²å°½åŠ›ä¸ºæ‚¨æ•´ç†ä¿¡æ¯ã€‚é”™è¯¯: {str(stream_error)}",
                    "status": "completed"
                }
                
                # æä¾›å¤‡ç”¨å›ç­”
                response_chunks.append("æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆè¯¦ç»†å›ç­”æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œä½†å·¥å…·æ‰§è¡Œç»“æœä»ç„¶æœ‰æ•ˆã€‚")
            
            # åˆå¹¶å®Œæ•´å“åº”å¹¶æ›´æ–°è®°å¿†
            full_response = "".join(response_chunks)
            memory_updated = await self._update_memory(context, message, full_response)
            
            yield {
                "type": "complete",
                "content": {
                    "memory_updated": memory_updated,
                    "tools_used": plan.get("tools", [])
                }
            }
            
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å¤±è´¥: {e}")
            yield {
                "type": "error",
                "content": f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            }

    async def _plan_response(self, message: str, context: ConversationContext, model: str = None) -> Dict[str, Any]:
        """
        è®¡åˆ’é˜¶æ®µ - åˆ†æç”¨æˆ·æ„å›¾å¹¶åˆ¶å®šå“åº”è®¡åˆ’
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            å“åº”è®¡åˆ’
        """
        system_prompt = f"""ä½ æ˜¯ç¾é£ŸAIåŠ©æ‰‹çš„è®¡åˆ’æ¨¡å—ã€‚è¯·åˆ†æç”¨æˆ·çš„æ¶ˆæ¯ï¼Œåˆ¤æ–­éœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·æ¥æœ€å¥½åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å¯ç”¨å·¥å…·ï¼š
- amap_search: é«˜å¾·åœ°å›¾æœç´¢ï¼ˆæŸ¥æ‰¾é¤å…ã€ç¾é£Ÿåœ°ç‚¹ï¼‰ã€å‚æ•°ï¼škeyword(å¿…éœ€)ã€‘
- bing_search: å¿…åº”æœç´¢ï¼ˆè·å–æœ€æ–°ä¿¡æ¯ï¼‰ã€å‚æ•°ï¼šquery(å¿…éœ€)ã€‘
- weather_api: å¤©æ°”APIï¼ˆè·å–å¤©æ°”ä¿¡æ¯ï¼‰ã€å‚æ•°ï¼šcity(å¿…éœ€)ã€‘
- food_recommendation: ç¾é£Ÿæ¨èã€å‚æ•°ï¼špreferences(å¯é€‰)ã€‘
- image_search: å›¾ç‰‡æœç´¢ï¼ˆå½“ç”¨æˆ·è¦æ±‚"å›¾ç‰‡"ã€"ç…§ç‰‡"ã€"çœ‹çœ‹"ã€"å±•ç¤º"ã€"æœç´¢å›¾ç‰‡"æ—¶ä½¿ç”¨ï¼‰ã€å‚æ•°ï¼šquery(å¿…éœ€)ã€‘
- recipe_generator: èœè°±ç”Ÿæˆï¼ˆå½“ç”¨æˆ·è¦æ±‚"åšæ³•"ã€"èœè°±"ã€"æ€ä¹ˆåš"æ—¶ä½¿ç”¨ï¼‰ã€å‚æ•°ï¼šdish_name(å¿…éœ€)ã€‘

**é‡è¦è¯†åˆ«è§„åˆ™ï¼š**
1. å¦‚æœç”¨æˆ·æåˆ°"å›¾ç‰‡"ã€"ç…§ç‰‡"ã€"çœ‹çœ‹"ã€"å±•ç¤º"ã€"æœç´¢å›¾ç‰‡"ç­‰å…³é”®è¯ï¼Œå¿…é¡»ä½¿ç”¨image_searchå·¥å…·ï¼Œå‚æ•°åä¸ºquery
2. å¦‚æœç”¨æˆ·è¦æ±‚èœè°±æˆ–åšæ³•ï¼Œä½¿ç”¨recipe_generatorå·¥å…·ï¼Œå‚æ•°åä¸ºdish_name
3. å¦‚æœç”¨æˆ·è¯¢é—®é¤å…ä½ç½®ï¼Œä½¿ç”¨amap_searchå·¥å…·ï¼Œå‚æ•°åä¸ºkeyword
4. å¦‚æœç”¨æˆ·è¦æ±‚ç¾é£Ÿæ¨èï¼Œä½¿ç”¨food_recommendationå·¥å…·ï¼Œå‚æ•°åä¸ºpreferences

**å›¾ç‰‡æœç´¢queryç”Ÿæˆè§„åˆ™ï¼š**
- åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œä¸»åŠ¨ç”Ÿæˆæœ€ä¼˜çš„æœç´¢å…³é”®è¯ï¼ˆä¸æ˜¯ç®€å•æå–ï¼‰
- æ ¹æ®é£Ÿç‰©ç±»å‹æ™ºèƒ½å¢å¼ºå…³é”®è¯ä»¥æé«˜æœç´¢æ•ˆæœ
- ä¾‹å¦‚ï¼š"ç»™æˆ‘çœ‹çœ‹çº¢çƒ§è‚‰çš„å›¾ç‰‡" â†’ åˆ†æï¼šç”¨æˆ·è¦çº¢çƒ§è‚‰å›¾ç‰‡ â†’ ç”Ÿæˆquery: "çº¢çƒ§è‚‰ ç¾é£Ÿ æˆå“"
- ä¾‹å¦‚ï¼š"æˆ‘æƒ³çœ‹çœ‹å·èœçš„ç…§ç‰‡" â†’ åˆ†æï¼šç”¨æˆ·è¦å·èœå›¾ç‰‡ â†’ ç”Ÿæˆquery: "å·èœ èœè°± ç‰¹è‰²èœ"
- ä¾‹å¦‚ï¼š"å±•ç¤ºä¸€äº›æ„å¤§åˆ©é¢çš„å›¾ç‰‡" â†’ åˆ†æï¼šç”¨æˆ·è¦æ„å¤§åˆ©é¢å›¾ç‰‡ â†’ ç”Ÿæˆquery: "æ„å¤§åˆ©é¢ pasta ç¾é£Ÿ"
- æ€è€ƒï¼šä»€ä¹ˆå…³é”®è¯ç»„åˆèƒ½æœåˆ°æœ€ç›¸å…³çš„å›¾ç‰‡ï¼Ÿè€Œä¸æ˜¯ç®€å•å»é™¤ä¿®é¥°è¯

ç”¨æˆ·åå¥½ï¼š{context.preferences}
å½“å‰ä½ç½®ï¼š{context.current_location}
å¯ç”¨å·¥å…·ï¼š{context.enabled_tools}

è¯·è¿”å›JSONæ ¼å¼çš„è®¡åˆ’ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼ï¼‰ï¼š
{{
    "intent": "ç”¨æˆ·æ„å›¾æè¿°",
    "tools": ["éœ€è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨"],
    "parameters": {{"å·¥å…·å": {{"å‚æ•°": "å€¼"}}}},
    "response_type": "text/recipe/recommendation/location"
}}

ç”¨æˆ·æ¶ˆæ¯ï¼š{message}"""

        try:
            # è·å–æŒ‡å®šæ¨¡å‹çš„å®¢æˆ·ç«¯å’Œé…ç½®
            ai_client, model_config = self._get_ai_client(model)
            
            response = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            plan_text = response.choices[0].message.content
            
            # å°è¯•è§£æJSON
            try:
                plan = json.loads(plan_text)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œä½¿ç”¨è§„åˆ™å¼•æ“åˆ›å»ºè®¡åˆ’
                plan = self._create_fallback_plan(message)
            
            # è¿‡æ»¤ä¸å¯ç”¨çš„å·¥å…·
            if context.enabled_tools:
                plan["tools"] = [tool for tool in plan.get("tools", []) if tool in context.enabled_tools]
            
            return plan
            
        except Exception as e:
            logger.error(f"åˆ¶å®šè®¡åˆ’å¤±è´¥: {e}")
            # ä½¿ç”¨è§„åˆ™å¼•æ“ä½œä¸ºå›é€€
            return self._create_fallback_plan(message)
    
    def _create_fallback_plan(self, message: str) -> Dict[str, Any]:
        """
        åŸºäºè§„åˆ™çš„å›é€€è®¡åˆ’ç”Ÿæˆå™¨
        å½“AIæ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨
        """
        message_lower = message.lower()
        
        # å›¾ç‰‡æœç´¢å…³é”®è¯
        image_keywords = ['å›¾ç‰‡', 'ç…§ç‰‡', 'çœ‹çœ‹', 'å±•ç¤º', 'æœç´¢å›¾ç‰‡', 'æ˜¾ç¤º', 'å›¾åƒ', 'çœ‹ä¸€ä¸‹', 'ç§ç§']
        # èœè°±å…³é”®è¯
        recipe_keywords = ['åšæ³•', 'èœè°±', 'æ€ä¹ˆåš', 'åˆ¶ä½œæ–¹æ³•', 'çƒ¹é¥ª', 'æ–™ç†', 'æ­¥éª¤']
        # æ¨èå…³é”®è¯
        recommendation_keywords = ['æ¨è', 'å»ºè®®', 'ä»€ä¹ˆå¥½åƒ', 'åƒä»€ä¹ˆ']
        # åœ°å›¾æœç´¢å…³é”®è¯
        location_keywords = ['é™„è¿‘', 'é¤å…', 'é¥­åº—', 'å“ªé‡Œæœ‰', 'åœ°å€', 'ä½ç½®']
        
        plan = {
            "intent": "å›ç­”ç”¨æˆ·å…³äºç¾é£Ÿçš„é—®é¢˜",
            "tools": [],
            "parameters": {},
            "response_type": "text"
        }
        
        # æ£€æŸ¥å›¾ç‰‡æœç´¢éœ€æ±‚
        if any(keyword in message_lower for keyword in image_keywords):
            plan["intent"] = "æœç´¢ç¾é£Ÿå›¾ç‰‡"
            plan["tools"].append("image_search")
            plan["response_type"] = "image"
            
            # æ™ºèƒ½ç”Ÿæˆæœç´¢å…³é”®è¯
            search_query = self._generate_smart_image_query(message)
            
            plan["parameters"]["image_search"] = {
                "query": search_query,
                "count": 5
            }
        
        # æ£€æŸ¥èœè°±éœ€æ±‚
        elif any(keyword in message_lower for keyword in recipe_keywords):
            plan["intent"] = "ç”Ÿæˆèœè°±å¹¶å±•ç¤ºå›¾ç‰‡"
            plan["tools"].extend(["recipe_generator", "image_search"])  # åŒæ—¶æ·»åŠ å›¾ç‰‡æœç´¢
            plan["response_type"] = "recipe"
            
            # ä»æ¶ˆæ¯ä¸­æå–é£Ÿç‰©åç§°
            food_name = self._extract_food_name_simple(message)
            dish_name = food_name if food_name else "å®¶å¸¸èœ"
            
            plan["parameters"]["recipe_generator"] = {
                "dish_name": dish_name
            }
            
            # åŒæ—¶æœç´¢ç›¸å…³å›¾ç‰‡ä»¥å¢å¼ºç”¨æˆ·ä½“éªŒ
            search_query = self._enhance_search_keywords(dish_name, message)
            plan["parameters"]["image_search"] = {
                "query": search_query
            }
        
        # æ£€æŸ¥æ¨èéœ€æ±‚
        elif any(keyword in message_lower for keyword in recommendation_keywords):
            plan["intent"] = "ç¾é£Ÿæ¨è"
            plan["tools"].append("food_recommendation")
            plan["response_type"] = "recommendation"
            
            plan["parameters"]["food_recommendation"] = {
                "preferences": {},
                "count": 5
            }
        
        # æ£€æŸ¥ä½ç½®æœç´¢éœ€æ±‚
        elif any(keyword in message_lower for keyword in location_keywords):
            plan["intent"] = "æœç´¢é¤å…ä½ç½®"
            plan["tools"].append("amap_search")
            plan["response_type"] = "location"
            
            # æå–å…³é”®è¯
            keyword = "é¤å…"
            for word in ['ç«é”…', 'å·èœ', 'ç²¤èœ', 'æ¹˜èœ', 'çƒ§çƒ¤', 'è¥¿é¤']:
                if word in message:
                    keyword = word
                    break
            
            plan["parameters"]["amap_search"] = {
                "keyword": keyword
            }
        
        logger.info(f"ä½¿ç”¨å›é€€è®¡åˆ’: {plan}")
        return plan
    
    def _generate_smart_image_query(self, message: str) -> str:
        """
        æ ¹æ®ç”¨æˆ·æ¶ˆæ¯æ™ºèƒ½ç”Ÿæˆå›¾ç‰‡æœç´¢å…³é”®è¯
        
        Args:
            message: ç”¨æˆ·åŸå§‹æ¶ˆæ¯
            
        Returns:
            ä¼˜åŒ–çš„æœç´¢å…³é”®è¯ç»„åˆ
        """
        import re
        
        # é¦–å…ˆæå–åŸºæœ¬çš„é£Ÿç‰©åç§°
        base_food = self._extract_food_name_simple(message)
        
        # æ ¹æ®é£Ÿç‰©ç±»å‹å’Œæ¶ˆæ¯å†…å®¹æ™ºèƒ½å¢å¼ºå…³é”®è¯
        enhanced_query = self._enhance_search_keywords(base_food, message)
        
        return enhanced_query
    
    def _extract_food_name_simple(self, message: str) -> str:
        """
        ä»ç”¨æˆ·æ¶ˆæ¯ä¸­ç®€å•æå–é£Ÿç‰©åç§°
        
        Args:
            message: ç”¨æˆ·åŸå§‹æ¶ˆæ¯
            
        Returns:
            æå–çš„é£Ÿç‰©åç§°
        """
        import re
        
        # å®šä¹‰è¦æ¸…ç†çš„åœç”¨è¯ï¼ˆæŒ‰é•¿åº¦æ’åºï¼Œå…ˆåŒ¹é…é•¿çš„ï¼‰
        stop_words = [
            # é•¿çŸ­è¯­ä¼˜å…ˆ
            'ç»™æˆ‘çœ‹çœ‹', 'æˆ‘æƒ³çœ‹çœ‹', 'è¯·æœç´¢', 'èƒ½ç»™æˆ‘', 'éº»çƒ¦ç»™', 'èƒ½å¦ç»™æˆ‘',
            # åŠ¨ä½œè¯
            'ç»™æˆ‘', 'å¸®æˆ‘', 'æˆ‘æƒ³', 'è¯·', 'èƒ½å¦', 'å¯ä»¥', 'éº»çƒ¦', 'èƒ½',
            # å±•ç¤ºè¯
            'çœ‹çœ‹', 'å±•ç¤º', 'æ˜¾ç¤º', 'æœç´¢', 'æ‰¾', 'æŸ¥æ‰¾', 'ç§ç§', 'çœ‹',
            # å›¾ç‰‡è¯
            'å›¾ç‰‡', 'ç…§ç‰‡', 'å›¾åƒ', 'å›¾', 'ç›¸ç‰‡', 'ç…§',
            # é‡è¯å’Œä¿®é¥°è¯
            'ä¸€äº›', 'å‡ å¼ ', 'å‡ ä¸ª', 'ä¸€ç‚¹', 'å‡ ç§', 'ä¸€å¼ ', 'ä¸€ä¸‹', 'æˆå“', 'åˆ¶ä½œ',
            # åŠ©è¯
            'çš„', 'äº†', 'å—', 'å‘¢', 'å§', 'å•Š', 'å‘€'
        ]
        
        # å¼€å§‹æ¸…ç†æ¶ˆæ¯
        cleaned = message.strip()
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        cleaned = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘\[\](),.!?:;"\'\-]', '', cleaned)
        
        # æŒ‰é¡ºåºç§»é™¤åœç”¨è¯
        for stop_word in stop_words:
            cleaned = cleaned.replace(stop_word, '')
        
        # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', '', cleaned).strip()
        
        # å¦‚æœç»“æœä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™æ¨¡å¼åŒ¹é…
        if not cleaned or len(cleaned) < 2:
            # å°è¯•åŒ¹é…å¸¸è§çš„ç¾é£Ÿåç§°æ¨¡å¼
            food_patterns = [
                r'([ä¸€-é¾¯]*[è‚‰][ä¸€-é¾¯]*)',        # åŒ…å«"è‚‰"çš„è¯
                r'([ä¸€-é¾¯]*[é±¼è™¾èŸ¹è›‹][ä¸€-é¾¯]*)',   # åŒ…å«æµ·é²œè›‹ç±»çš„è¯
                r'([ä¸€-é¾¯]*[èœ][ä¸€-é¾¯]*)',        # åŒ…å«"èœ"çš„è¯  
                r'([ä¸€-é¾¯]*[æ±¤ç²¥é¢æ¡é¥­][ä¸€-é¾¯]*)', # åŒ…å«ä¸»é£Ÿçš„è¯
                r'([ä¸€-é¾¯]*[ç³–é¥¼å¹²è›‹ç³•][ä¸€-é¾¯]*)', # åŒ…å«ç”œå“çš„è¯
                r'([ä¸€-é¾¯]*[è±†è…][ä¸€-é¾¯]*)',      # åŒ…å«è±†è…çš„è¯
            ]
            
            for pattern in food_patterns:
                matches = re.findall(pattern, message)
                if matches:
                    # é€‰æ‹©æœ€é•¿çš„åŒ¹é…
                    longest_match = max(matches, key=len)
                    if len(longest_match) >= 2:
                        cleaned = longest_match
                        break
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ç»“æœï¼Œè¿”å›é»˜è®¤å€¼
        if not cleaned or len(cleaned) < 2:
            return "ç¾é£Ÿ"
        
        # é™åˆ¶é•¿åº¦ï¼Œé˜²æ­¢è¿‡é•¿
        if len(cleaned) > 8:
            cleaned = cleaned[:8]
        
        return cleaned
    
    def _enhance_search_keywords(self, base_food: str, original_message: str) -> str:
        """
        æ ¹æ®é£Ÿç‰©ç±»å‹æ™ºèƒ½å¢å¼ºæœç´¢å…³é”®è¯
        
        Args:
            base_food: åŸºç¡€é£Ÿç‰©åç§°
            original_message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            å¢å¼ºåçš„æœç´¢å…³é”®è¯ç»„åˆ
        """
        # èœç³»å’Œç‰¹è‰²å…³é”®è¯æ˜ å°„
        cuisine_keywords = {
            # ä¸­å¼èœç³»
            'çº¢çƒ§è‚‰': 'çº¢çƒ§è‚‰ å®¶å¸¸èœ ç¾é£Ÿ',
            'å®«ä¿é¸¡ä¸': 'å®«ä¿é¸¡ä¸ å·èœ ç»å…¸',
            'éº»å©†è±†è…': 'éº»å©†è±†è… å·èœ è±†è…',
            'ç³–é†‹é‡Œè„Š': 'ç³–é†‹é‡Œè„Š é…¸ç”œ å®¶å¸¸èœ',
            'å›é”…è‚‰': 'å›é”…è‚‰ å·èœ å®¶å¸¸',
            'é±¼é¦™è‚‰ä¸': 'é±¼é¦™è‚‰ä¸ å·èœ ä¸‹é¥­èœ',
            
            # èœç³»åˆ†ç±»
            'å·èœ': 'å·èœ å››å·èœ éº»è¾£',
            'ç²¤èœ': 'ç²¤èœ å¹¿ä¸œèœ æ¸…æ·¡',
            'æ¹˜èœ': 'æ¹˜èœ æ¹–å—èœ è¾£æ¤’',
            'é²èœ': 'é²èœ å±±ä¸œèœ ä¼ ç»Ÿ',
            
            # å›½é™…ç¾é£Ÿ
            'æ„å¤§åˆ©é¢': 'æ„å¤§åˆ©é¢ pasta è¥¿é¤',
            'ç‰›æ’': 'ç‰›æ’ steak è¥¿é¤',
            'å¯¿å¸': 'å¯¿å¸ æ—¥æœ¬æ–™ç† ç”Ÿé±¼ç‰‡',
            'æ‹‰é¢': 'æ‹‰é¢ æ—¥å¼ æ±¤é¢',
            'æŠ«è¨': 'æŠ«è¨ pizza è¥¿é¤',
            
            # ç”œå“ç±»
            'è›‹ç³•': 'è›‹ç³• ç”œå“ çƒ˜ç„™',
            'å¥¶èŒ¶': 'å¥¶èŒ¶ é¥®å“ çç ',
            'å†°æ·‡æ·‹': 'å†°æ·‡æ·‹ ç”œå“ å¤å­£',
            
            # ä¸»é£Ÿç±»
            'åŒ…å­': 'åŒ…å­ æ—©é¤ è’¸',
            'é¥ºå­': 'é¥ºå­ ä¼ ç»Ÿ é¢é£Ÿ',
            'é¢æ¡': 'é¢æ¡ ä¸»é£Ÿ æ±¤é¢',
            'ç±³é¥­': 'ç±³é¥­ ä¸»é£Ÿ æ­é…'
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é¢„å®šä¹‰çš„å…³é”®è¯ç»„åˆ
        if base_food in cuisine_keywords:
            return cuisine_keywords[base_food]
        
        # æ ¹æ®é£Ÿç‰©ç‰¹å¾åŠ¨æ€ç”Ÿæˆå…³é”®è¯
        enhanced_query = base_food
        
        # åˆ¤æ–­é£Ÿç‰©ç±»å‹å¹¶æ·»åŠ ç›¸åº”å…³é”®è¯
        if any(word in base_food for word in ['è‚‰', 'é¸¡', 'é¸­', 'é±¼', 'è™¾', 'èŸ¹']):
            enhanced_query += ' ç¾é£Ÿ è¤èœ'
        elif any(word in base_food for word in ['èœ', 'è±†è…', 'èåœ', 'åœŸè±†']):
            enhanced_query += ' è”¬èœ å®¶å¸¸èœ'
        elif any(word in base_food for word in ['é¢', 'é¥­', 'ç²¥', 'åŒ…å­', 'é¥ºå­']):
            enhanced_query += ' ä¸»é£Ÿ ä¼ ç»Ÿ'
        elif any(word in base_food for word in ['æ±¤', 'ç¾¹']):
            enhanced_query += ' æ±¤å“ è¥å…»'
        elif any(word in base_food for word in ['ç³•', 'é¥¼', 'ç”œ']):
            enhanced_query += ' ç”œå“ çƒ˜ç„™'
        else:
            enhanced_query += ' ç¾é£Ÿ èœè°±'
        
        # å¦‚æœç”¨æˆ·æåˆ°ç‰¹å®šéœ€æ±‚ï¼Œæ·»åŠ ç›¸åº”å…³é”®è¯
        if any(word in original_message for word in ['åšæ³•', 'åˆ¶ä½œ', 'æ­¥éª¤']):
            enhanced_query += ' åˆ¶ä½œè¿‡ç¨‹'
        elif any(word in original_message for word in ['æˆå“', 'å®Œæˆ', 'æœ€ç»ˆ']):
            enhanced_query += ' æˆå“å›¾'
        elif any(word in original_message for word in ['ææ–™', 'é£Ÿæ']):
            enhanced_query += ' é£Ÿæ'
        
        return enhanced_query

    async def _stream_user_intent_analysis(self, message: str, context: ConversationContext, model: str = None) -> AsyncGenerator[str, None]:
        """
        æµå¼åˆ†æç”¨æˆ·æ„å›¾ï¼ˆæ€ç»´é“¾ç¬¬ä¸€æ­¥ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Yields:
            æ„å›¾åˆ†æå†…å®¹å—
        """
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾é£ŸAIåŠ©æ‰‹ï¼Œæ­£åœ¨åˆ†æç”¨æˆ·çš„é—®é¢˜ã€‚è¯·è¯¦ç»†åˆ†æç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚ã€‚

ç”¨æˆ·çš„å†å²åå¥½ï¼š{context.preferences}
å½“å‰å¯ç”¨å·¥å…·ï¼š{context.enabled_tools}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼åˆ†æç”¨æˆ·æ„å›¾ï¼š
1. ç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ
2. ç”¨æˆ·å¯èƒ½æœŸæœ›ä»€ä¹ˆæ ·çš„å›ç­”ï¼Ÿ  
3. è¿™ä¸ªé—®é¢˜çš„éš¾åº¦å¦‚ä½•ï¼Ÿ
4. éœ€è¦å“ªäº›ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼Ÿ

è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€åˆ†æï¼Œè®©ç”¨æˆ·èƒ½çœ‹æ‡‚ä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{message}"""

        try:
            ai_client, model_config = self._get_ai_client(model)
            
            stream = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=800,
                temperature=0.7,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"æµå¼æ„å›¾åˆ†æå¤±è´¥: {e}")
            yield f"æˆ‘æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼šã€Œ{message}ã€\n\nçœ‹èµ·æ¥æ‚¨æƒ³äº†è§£ç¾é£Ÿç›¸å…³çš„ä¿¡æ¯ï¼Œè®©æˆ‘ä¸ºæ‚¨æŸ¥æ‰¾ç›¸å…³èµ„æ–™ã€‚"

    async def _analyze_user_intent(self, message: str, context: ConversationContext, model: str = None) -> str:
        """
        åˆ†æç”¨æˆ·æ„å›¾ï¼ˆæ€ç»´é“¾ç¬¬ä¸€æ­¥ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            æ„å›¾åˆ†æç»“æœ
        """
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾é£ŸAIåŠ©æ‰‹ï¼Œæ­£åœ¨åˆ†æç”¨æˆ·çš„é—®é¢˜ã€‚è¯·è¯¦ç»†åˆ†æç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚ã€‚

ç”¨æˆ·çš„å†å²åå¥½ï¼š{context.preferences}
å½“å‰å¯ç”¨å·¥å…·ï¼š{context.enabled_tools}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼åˆ†æç”¨æˆ·æ„å›¾ï¼š
1. ç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ
2. ç”¨æˆ·å¯èƒ½æœŸæœ›ä»€ä¹ˆæ ·çš„å›ç­”ï¼Ÿ  
3. è¿™ä¸ªé—®é¢˜çš„éš¾åº¦å¦‚ä½•ï¼Ÿ
4. éœ€è¦å“ªäº›ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼Ÿ

è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€åˆ†æï¼Œè®©ç”¨æˆ·èƒ½çœ‹æ‡‚ä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{message}"""

        try:
            ai_client, model_config = self._get_ai_client(model)
            
            response = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"æ„å›¾åˆ†æå¤±è´¥: {e}")
            return f"æˆ‘æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼šã€Œ{message}ã€\n\nçœ‹èµ·æ¥æ‚¨æƒ³äº†è§£ç¾é£Ÿç›¸å…³çš„ä¿¡æ¯ï¼Œè®©æˆ‘ä¸ºæ‚¨æŸ¥æ‰¾ç›¸å…³èµ„æ–™ã€‚"

    async def _plan_response_with_thinking(self, message: str, context: ConversationContext, model: str = None) -> Dict[str, Any]:
        """
        å¸¦æ€ç»´é“¾çš„è®¡åˆ’åˆ¶å®š
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            è¯¦ç»†çš„å“åº”è®¡åˆ’
        """
        system_prompt = f"""ä½ æ˜¯ç¾é£ŸAIåŠ©æ‰‹çš„è®¡åˆ’æ¨¡å—ã€‚è¯·åˆ†æç”¨æˆ·çš„æ¶ˆæ¯ï¼Œåˆ¶å®šè¯¦ç»†çš„å›ç­”ç­–ç•¥ã€‚

å¯ç”¨å·¥å…·ï¼š
- amap_search: é«˜å¾·åœ°å›¾æœç´¢ï¼ˆæŸ¥æ‰¾é¤å…ã€ç¾é£Ÿåœ°ç‚¹ï¼‰ã€å‚æ•°ï¼škeyword(å¿…éœ€)ã€‘
- bing_search: å¿…åº”æœç´¢ï¼ˆè·å–æœ€æ–°ä¿¡æ¯ï¼‰ã€å‚æ•°ï¼šquery(å¿…éœ€)ã€‘
- weather_api: å¤©æ°”APIï¼ˆè·å–å¤©æ°”ä¿¡æ¯ï¼‰ã€å‚æ•°ï¼šcity(å¿…éœ€)ã€‘
- food_recommendation: ç¾é£Ÿæ¨èã€å‚æ•°ï¼špreferences(å¯é€‰)ã€‘
- image_search: å›¾ç‰‡æœç´¢ï¼ˆå½“ç”¨æˆ·è¦æ±‚"å›¾ç‰‡"ã€"ç…§ç‰‡"ã€"çœ‹çœ‹"ã€"å±•ç¤º"ã€"æœç´¢å›¾ç‰‡"æ—¶ä½¿ç”¨ï¼‰ã€å‚æ•°ï¼šquery(å¿…éœ€)ã€‘
- recipe_generator: èœè°±ç”Ÿæˆï¼ˆå½“ç”¨æˆ·è¦æ±‚"åšæ³•"ã€"èœè°±"ã€"æ€ä¹ˆåš"æ—¶ä½¿ç”¨ï¼‰ã€å‚æ•°ï¼šdish_name(å¿…éœ€)ã€‘

**å›¾ç‰‡æœç´¢å…³é”®è¯ç”Ÿæˆç­–ç•¥ï¼š**
- åˆ†æç”¨æˆ·çœŸæ­£æƒ³çœ‹çš„å†…å®¹
- æ ¹æ®é£Ÿç‰©ç±»å‹æ™ºèƒ½å¢å¼ºå…³é”®è¯
- ä¾‹å¦‚ï¼š"çº¢çƒ§è‚‰çš„å›¾ç‰‡" â†’ åˆ†æï¼šç”¨æˆ·è¦çœ‹çº¢çƒ§è‚‰æˆå“ â†’ ç”Ÿæˆquery: "çº¢çƒ§è‚‰ ç¾é£Ÿ æˆå“"

ç”¨æˆ·åå¥½ï¼š{context.preferences}
å½“å‰ä½ç½®ï¼š{context.current_location}
å¯ç”¨å·¥å…·ï¼š{context.enabled_tools}

è¯·è¿”å›JSONæ ¼å¼çš„è¯¦ç»†è®¡åˆ’ï¼š
{{
    "intent": "ç”¨æˆ·æ„å›¾æè¿°", 
    "tools": ["éœ€è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨"],
    "parameters": {{"å·¥å…·å": {{"å‚æ•°": "å€¼"}}}},
    "response_type": "text/recipe/recommendation/location/image",
    "strategy": "å›ç­”ç­–ç•¥æè¿°",
    "reasoning": "é€‰æ‹©è¿™ä¸ªç­–ç•¥çš„åŸå› "
}}

ç”¨æˆ·æ¶ˆæ¯ï¼š{message}"""

        try:
            ai_client, model_config = self._get_ai_client(model)
            
            response = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            plan_text = response.choices[0].message.content
            
            try:
                plan = json.loads(plan_text)
            except json.JSONDecodeError:
                plan = self._create_fallback_plan(message)
                plan["strategy"] = "ä½¿ç”¨å¤‡ç”¨ç­–ç•¥å›ç­”ç”¨æˆ·é—®é¢˜"
                plan["reasoning"] = "AIæ¨¡å‹è¿”å›æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨è§„åˆ™å¼•æ“"
            
            # è¿‡æ»¤ä¸å¯ç”¨çš„å·¥å…·
            if context.enabled_tools:
                plan["tools"] = [tool for tool in plan.get("tools", []) if tool in context.enabled_tools]
            
            return plan
            
        except Exception as e:
            logger.error(f"åˆ¶å®šæ€ç»´é“¾è®¡åˆ’å¤±è´¥: {e}")
            plan = self._create_fallback_plan(message)
            plan["strategy"] = "ä½¿ç”¨å¤‡ç”¨ç­–ç•¥å›ç­”ç”¨æˆ·é—®é¢˜"
            plan["reasoning"] = f"AIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"
            return plan

    async def _execute_single_tool(self, tool_name: str, plan: Dict, context: ConversationContext) -> Dict:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            plan: æ‰§è¡Œè®¡åˆ’
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            parameters = plan.get("parameters", {}).get(tool_name, {})
            result = await self.mcp_manager.execute_tool(tool_name, parameters)
            return result
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def _execute_actions_with_thinking(self, plan: Dict[str, Any], context: ConversationContext, model: str = None) -> Dict[str, Any]:
        """
        å¸¦æ€ç»´é“¾çš„å·¥å…·æ‰§è¡Œ
        """
        return await self._execute_actions(plan, context, model)

    async def _stream_response_with_thinking(
        self, 
        message: str, 
        context: ConversationContext, 
        plan: Dict[str, Any], 
        action_results: Dict[str, Any],
        model: str = None
    ) -> AsyncGenerator[str, None]:
        """
        å¸¦æ€ç»´é“¾çš„æµå¼å›å¤ç”Ÿæˆ
        """
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šæ€ç»´è¿‡ç¨‹ï¼Œç°åœ¨å…ˆä½¿ç”¨åŸæœ‰çš„ç”Ÿæˆæ–¹æ³•
        async for chunk in self._stream_response(message, context, plan, action_results, model):
            yield chunk

    async def _execute_actions(self, plan: Dict[str, Any], context: ConversationContext, model: str = None) -> Dict[str, Any]:
        """
        è¡ŒåŠ¨é˜¶æ®µ - æ‰§è¡Œè®¡åˆ’ä¸­çš„å·¥å…·è°ƒç”¨
        
        Args:
            plan: å“åº”è®¡åˆ’
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            model: ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        action_results = {}
        
        for tool_name in plan.get("tools", []):
            try:
                parameters = plan.get("parameters", {}).get(tool_name, {})
                
                # å¦‚æœæ˜¯èœè°±ç”Ÿæˆå·¥å…·ï¼Œæ·»åŠ æ¨¡å‹ä¿¡æ¯
                if tool_name == "recipe_generator" and model:
                    parameters["model_id"] = model
                
                result = await self.mcp_manager.execute_tool(tool_name, parameters)
                
                # ä¸ºç»“æœæ·»åŠ å±•ç¤ºç±»å‹ä¿¡æ¯
                enhanced_result = self._enhance_tool_result(tool_name, result)
                action_results[tool_name] = enhanced_result
                
                logger.info(f"å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                
            except Exception as e:
                logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
                action_results[tool_name] = {
                    "error": str(e),
                    "display_type": "error",
                    "tool_name": tool_name
                }
        
        return action_results

    def _enhance_tool_result(self, tool_name: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºå·¥å…·ç»“æœæ·»åŠ å±•ç¤ºç±»å‹ä¿¡æ¯ï¼Œä¼˜åŒ–å‰ç«¯å±•ç¤º
        
        Args:
            tool_name: å·¥å…·åç§°
            result: åŸå§‹å·¥å…·ç»“æœ
            
        Returns:
            å¢å¼ºåçš„ç»“æœï¼ŒåŒ…å«å±•ç¤ºä¿¡æ¯
        """
        enhanced_result = result.copy()
        enhanced_result["tool_name"] = tool_name
        
        # æ ¹æ®å·¥å…·ç±»å‹æ·»åŠ å±•ç¤ºä¿¡æ¯
        if tool_name == "image_search":
            enhanced_result["display_type"] = "image_gallery"
            enhanced_result["display_config"] = {
                "layout": "grid",
                "columns": 3,
                "show_modal": True,
                "lazy_load": True
            }
            # ç¡®ä¿å›¾ç‰‡æ•°æ®æ ¼å¼æ­£ç¡®
            # æ£€æŸ¥å·¥å…·ç»“æœçš„åµŒå¥—ç»“æ„
            tool_result = result.get("result", result)  # MCPåŒ…è£…åçš„ç»“æœ
            if "images" in tool_result and isinstance(tool_result["images"], list):
                enhanced_result["display_data"] = {
                    "images": tool_result["images"],
                    "total": len(tool_result["images"]),
                    "query": tool_result.get("query", "")
                }
            else:
                # å¦‚æœæ²¡æœ‰å›¾ç‰‡æ•°æ®ï¼Œæä¾›é»˜è®¤ç»“æ„
                enhanced_result["display_data"] = {
                    "images": [],
                    "total": 0,
                    "query": tool_result.get("query", ""),
                    "message": tool_result.get("message", "æœªæ‰¾åˆ°å›¾ç‰‡")
                }
        
        elif tool_name == "food_recommendation":
            enhanced_result["display_type"] = "recommendation_cards"
            enhanced_result["display_config"] = {
                "layout": "card_grid", 
                "show_ratings": True,
                "show_difficulty": True,
                "interactive": True
            }
            # æ ¼å¼åŒ–æ¨èæ•°æ®
            tool_result = result.get("result", result)
            if "recommendations" in tool_result:
                enhanced_result["display_data"] = {
                    "recommendations": tool_result["recommendations"],
                    "total_count": tool_result.get("total_count", 0),
                    "categories": self._extract_recommendation_categories(tool_result["recommendations"])
                }
            else:
                enhanced_result["display_data"] = {
                    "recommendations": [],
                    "total_count": 0,
                    "categories": []
                }
        
        elif tool_name == "recipe_generator":
            enhanced_result["display_type"] = "recipe_detailed"
            enhanced_result["display_config"] = {
                "layout": "detailed_card",
                "show_nutrition": True,
                "show_steps": True,
                "interactive": True,
                "printable": True
            }
            # æ ¼å¼åŒ–èœè°±æ•°æ®
            tool_result = result.get("result", result)
            if "data" in tool_result:
                recipe_data = tool_result["data"]
                enhanced_result["display_data"] = {
                    "recipe": recipe_data,
                    "metadata": {
                        "prep_time": recipe_data.get("prep_time", ""),
                        "cook_time": recipe_data.get("cook_time", ""),
                        "difficulty": recipe_data.get("difficulty", ""),
                        "serving_size": recipe_data.get("serving_size", "")
                    }
                }
            else:
                enhanced_result["display_data"] = {
                    "recipe": {},
                    "metadata": {
                        "prep_time": "",
                        "cook_time": "",
                        "difficulty": "",
                        "serving_size": ""
                    }
                }
        
        elif tool_name == "amap_search":
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å·²ç»è¿”å›äº†æ­£ç¡®çš„æ˜¾ç¤ºæ ¼å¼
            tool_result = result.get("result", result)
            
            # å¦‚æœå·¥å…·å·²ç»æä¾›äº†display_typeï¼Œä½¿ç”¨å·¥å…·çš„æ ¼å¼
            if "display_type" in tool_result:
                enhanced_result.update(tool_result)
            else:
                # å›é€€åˆ°é»˜è®¤æ ¼å¼åŒ–
                enhanced_result["display_type"] = "location_list"
                enhanced_result["display_config"] = {
                    "layout": "list_with_map",
                    "show_distance": True,
                    "show_rating": True,
                    "interactive": True
                }
                # æ ¼å¼åŒ–ä½ç½®æ•°æ®
                locations = tool_result.get("locations", [])
                if not locations:
                    # å…¼å®¹æ—§æ ¼å¼
                    locations = tool_result.get("results", [])
                
                enhanced_result["display_data"] = {
                    "locations": locations,
                    "search_query": tool_result.get("query", ""),
                    "total_found": len(locations)
                }
        
        elif tool_name == "weather_api":
            enhanced_result["display_type"] = "weather_card"
            enhanced_result["display_config"] = {
                "layout": "card_with_suggestions",
                "show_temperature": True,
                "show_suggestions": True,
                "animated": True
            }
            # æ ¼å¼åŒ–å¤©æ°”æ•°æ®
            tool_result = result.get("result", result)
            enhanced_result["display_data"] = {
                "weather": tool_result.get("weather", {}),
                "food_suggestions": tool_result.get("food_suggestions", []),
                "location": tool_result.get("location", "")
            }
        
        elif tool_name == "bing_search":
            enhanced_result["display_type"] = "search_results"
            enhanced_result["display_config"] = {
                "layout": "compact_list",
                "show_snippets": True,
                "max_results": 5
            }
            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            tool_result = result.get("result", result)
            enhanced_result["display_data"] = {
                "results": tool_result.get("results", []),
                "query": tool_result.get("query", ""),
                "total_results": tool_result.get("total_results", 0)
            }
        
        else:
            # é»˜è®¤å±•ç¤ºç±»å‹
            enhanced_result["display_type"] = "simple_text"
            enhanced_result["display_config"] = {
                "layout": "plain",
                "format": "json"
            }
            enhanced_result["display_data"] = result
        
        return enhanced_result
    
    def _extract_recommendation_categories(self, recommendations: List[Dict[str, Any]]) -> List[str]:
        """ä»æ¨èç»“æœä¸­æå–åˆ†ç±»"""
        categories = set()
        for rec in recommendations:
            if "category" in rec:
                categories.add(rec["category"])
        return list(categories)

    async def _generate_response(
        self, 
        message: str, 
        context: ConversationContext, 
        plan: Dict[str, Any], 
        action_results: Dict[str, Any],
        model: str = None
    ) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆå›å¤
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            plan: å“åº”è®¡åˆ’
            action_results: å·¥å…·æ‰§è¡Œç»“æœ
            
        Returns:
            AIå›å¤
        """
        personality_prompt = self.personality[self.current_personality]
        
        system_prompt = f"""{personality_prompt}

å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
- ç”¨æˆ·åå¥½ï¼š{context.preferences}
- å½“å‰ä½ç½®ï¼š{context.current_location}
- æ‰§è¡Œçš„å·¥å…·ï¼š{plan.get('tools', [])}
- å·¥å…·ç»“æœï¼š{action_results}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªæœ‰ç”¨ã€å‡†ç¡®ã€å‹å¥½çš„å›å¤ã€‚å¦‚æœä½¿ç”¨äº†å·¥å…·ï¼Œè¯·æ•´åˆå·¥å…·ç»“æœæ¥å¢å¼ºä½ çš„å›ç­”ã€‚"""

        try:
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
            recent_messages = context.messages[-10:]  # åªä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
            for msg in recent_messages:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # è·å–æŒ‡å®šæ¨¡å‹çš„å®¢æˆ·ç«¯å’Œé…ç½®
            ai_client, model_config = self._get_ai_client(model)
            
            response = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=messages,
                max_tokens=model_config.get('max_tokens', 2000),
                temperature=model_config.get('temperature', 0.7)
            )
            
            ai_response = response.choices[0].message.content
            
            # æ·»åŠ AIå›å¤åˆ°ä¸Šä¸‹æ–‡
            context.messages.append({
                "role": "assistant",
                "content": ai_response,
                "timestamp": datetime.now().isoformat()
            })
            
            return ai_response
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def _stream_response(
        self, 
        message: str, 
        context: ConversationContext, 
        plan: Dict[str, Any], 
        action_results: Dict[str, Any],
        model: str = None
    ) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆå›å¤"""
        personality_prompt = self.personality[self.current_personality]
        
        system_prompt = f"""{personality_prompt}

å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
- ç”¨æˆ·åå¥½ï¼š{context.preferences}
- å½“å‰ä½ç½®ï¼š{context.current_location}
- æ‰§è¡Œçš„å·¥å…·ï¼š{plan.get('tools', [])}
- å·¥å…·ç»“æœï¼š{action_results}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªæœ‰ç”¨ã€å‡†ç¡®ã€å‹å¥½çš„å›å¤ã€‚"""

        try:
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²
            recent_messages = context.messages[-10:]
            for msg in recent_messages:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # è·å–æŒ‡å®šæ¨¡å‹çš„å®¢æˆ·ç«¯å’Œé…ç½®
            ai_client, model_config = self._get_ai_client(model)
            
            stream = await ai_client.chat.completions.create(
                model=model_config['model'],
                messages=messages,
                max_tokens=model_config.get('max_tokens', 2000),
                temperature=model_config.get('temperature', 0.7),
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}")
            yield f"æŠ±æ­‰ï¼Œç”Ÿæˆå›å¤æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

    async def _update_memory(self, context: ConversationContext, user_message: str, ai_response: str) -> bool:
        """
        æ›´æ–°ç”¨æˆ·è®°å¿†
        
        Args:
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            user_message: ç”¨æˆ·æ¶ˆæ¯
            ai_response: AIå›å¤
            
        Returns:
            æ˜¯å¦æˆåŠŸæ›´æ–°è®°å¿†
        """
        try:
            # åˆ†æå¯¹è¯å†…å®¹ï¼Œæå–å¯è®°å¿†çš„ä¿¡æ¯
            memory_data = {
                "type": "conversation",
                "timestamp": datetime.now().isoformat(),
                "user_message": user_message,
                "ai_response": ai_response,
                "session_id": context.session_id
            }
            
            # æå–ç”¨æˆ·åå¥½
            preferences = await self._extract_preferences(user_message, ai_response)
            if preferences:
                memory_data["preferences"] = preferences
                context.preferences.update(preferences)
            
            # ä¿å­˜åˆ°è®°å¿†ç³»ç»Ÿ
            await self.memory_client.add_memory(
                user_id=context.user_id,
                memory_data=memory_data
            )
            
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°è®°å¿†å¤±è´¥: {e}")
            return False

    async def _extract_preferences(self, user_message: str, ai_response: str) -> Dict[str, Any]:
        """ä»å¯¹è¯ä¸­æå–ç”¨æˆ·åå¥½"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨NLPæŠ€æœ¯æˆ–è§„åˆ™æ¥æå–åå¥½
        # ç®€åŒ–å®ç°ï¼Œåç»­å¯ä»¥å®Œå–„
        preferences = {}
        
        # æ£€æµ‹å£å‘³åå¥½
        if any(word in user_message.lower() for word in ['è¾£', 'éº»è¾£', 'å·èœ']):
            preferences['spicy_preference'] = 'high'
        elif any(word in user_message.lower() for word in ['æ¸…æ·¡', 'ä¸è¾£']):
            preferences['spicy_preference'] = 'low'
        
        # æ£€æµ‹é¥®é£Ÿä¹ æƒ¯
        if any(word in user_message.lower() for word in ['ç´ é£Ÿ', 'vegetarian']):
            preferences['diet_type'] = 'vegetarian'
        elif any(word in user_message.lower() for word in ['å‡è‚¥', 'ä½çƒ­é‡']):
            preferences['health_goal'] = 'weight_loss'
        
        return preferences

    async def search_food(self, food_name: str, location: str = None, preferences: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æœç´¢ç¾é£Ÿä¿¡æ¯
        
        Args:
            food_name: é£Ÿç‰©åç§°
            location: ä½ç½®ä¿¡æ¯
            preferences: ç”¨æˆ·åå¥½
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            results = {}
            
            # ä½¿ç”¨å¤šä¸ªå·¥å…·æœç´¢
            if location and 'amap_search' in self.mcp_manager.available_tools:
                # æœç´¢é™„è¿‘é¤å…
                restaurant_results = await self.mcp_manager.execute_tool(
                    'amap_search',
                    {'keyword': food_name, 'location': location}
                )
                results['restaurants'] = restaurant_results
            
            if 'recipe_generator' in self.mcp_manager.available_tools:
                # ç”Ÿæˆèœè°±
                recipe_results = await self.mcp_manager.execute_tool(
                    'recipe_generator',
                    {'food_name': food_name, 'preferences': preferences}
                )
                results['recipe'] = recipe_results
            
            if 'image_search' in self.mcp_manager.available_tools:
                # æœç´¢å›¾ç‰‡
                image_results = await self.mcp_manager.execute_tool(
                    'image_search',
                    {'query': food_name}
                )
                results['images'] = image_results
            
            return {
                'success': True,
                'food_name': food_name,
                'results': results
            }
            
        except Exception as e:
            logger.error(f"æœç´¢ç¾é£Ÿå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            } 